{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Chapter4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yosshi3/python-season3/blob/master/pytorch/PyTorch_Chapter4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbYxdjYvOMzZ",
        "colab_type": "text"
      },
      "source": [
        "Chapter4　画像処理と畳み込みニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPIfITcaBxSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqiWwutIClJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.tensor([1,2,3]).to(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZhfQJ6-XF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import (Dataset, \n",
        "                              DataLoader,\n",
        "                              TensorDataset)\n",
        "import tqdm\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_wkLwK5Kmu2",
        "colab_type": "text"
      },
      "source": [
        "リスト4.1　Fashion-MNISTのデータからDataLoaderを作成（<your_path>は任意のディレクトリに変更）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcqPEZSd-8d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# 訓練用のデータを取得\n",
        "# そのままだとPIL（Python Imaging Library）の画像形式で\n",
        "# Datasetを作ってしまうので、\n",
        "# transforms.ToTensorでTensorに変換する\n",
        "fashion_mnist_train = FashionMNIST(\"<your_path>/FashionMNIST\", \n",
        "    train=True, download=True,\n",
        "    transform=transforms.ToTensor())\n",
        "# 検証用データの取得\n",
        "fashion_mnist_test = FashionMNIST(\"<your_path>/FashionMNIST\",\n",
        "    train=False, download=True,\n",
        "    transform=transforms.ToTensor())\n",
        "\n",
        "# バッチサイズが128のDataLoaderをそれぞれ作成\n",
        "batch_size=128\n",
        "train_loader = DataLoader(fashion_mnist_train, \n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(fashion_mnist_test,\n",
        "                         batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzK2zE0rLnGx",
        "colab_type": "text"
      },
      "source": [
        "リスト4.2　2層の畳み込み層と2層のMLPをつなげたCNNを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk_TuP1EOLjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  (N、C、H、W)形式のTensorを(N, C*H*W)に引き伸ばす層\n",
        "# 畳み込み層の出力をMLPに渡す際に必要\n",
        "class FlattenLayer(nn.Module):\n",
        "    def forward(self, x):\n",
        "        sizes = x.size()\n",
        "        return x.view(sizes[0], -1)\n",
        "\n",
        "# 5×5のカーネルを使用し最初に32個、次に64個のチャンネルを作成する\n",
        "# BatchNorm2dは画像形式用のBatch Normalization\n",
        "# Dropout2dは画像形式用のDropout\n",
        "# 最後にFlattenLayerを挟む\n",
        "conv_net = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.Dropout2d(0.25),\n",
        "    nn.Conv2d(32, 64, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.Dropout2d(0.25),\n",
        "    FlattenLayer()\n",
        ")\n",
        "\n",
        "# 畳み込みによって最終的にどのようなサイズになっているかを、\n",
        "# 実際にダミーデータを入れてみて確認する\n",
        "test_input = torch.ones(1, 1, 28, 28)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "\n",
        "# 2層のMLP\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(conv_output_size, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(200),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Linear(200, 10)\n",
        ")\n",
        "\n",
        "# 最終的なCNN\n",
        "net = nn.Sequential(\n",
        "    conv_net,\n",
        "    mlp\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOBu9DVFLq1Y",
        "colab_type": "text"
      },
      "source": [
        "リスト4.3　評価と訓練のヘルパー関数を作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETeREXcXOvky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 評価のヘルパー関数\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "    # DropoutやBatchNormを無効化\n",
        "    net.eval()\n",
        "    ys = []\n",
        "    ypreds = []\n",
        "    for x, y in data_loader:\n",
        "        # toメソッドで計算を実行するデバイスに転送する\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # 確率が最大のクラスを予測(リスト2.14参照)\n",
        "        # ここではforward（推論）の計算だけなので自動微分に\n",
        "        # 必要な処理はoffにして余計な計算を省く\n",
        "        with torch.no_grad():\n",
        "            _, y_pred = net(x).max(1)\n",
        "        ys.append(y)\n",
        "        ypreds.append(y_pred)\n",
        "            # ミニバッチごとの予測結果などを1つにまとめる\n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "    # 予測精度を計算\n",
        "    acc = (ys == ypreds).float().sum() / len(ys)\n",
        "    return acc.item()\n",
        "  \n",
        "# 訓練のヘルパー関数\n",
        "def train_net(net, train_loader, test_loader,\n",
        "              optimizer_cls=optim.Adam,\n",
        "              loss_fn=nn.CrossEntropyLoss(),\n",
        "              n_iter=10, device=\"cpu\"):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    optimizer = optimizer_cls(net.parameters())\n",
        "    for epoch in range(n_iter):\n",
        "        running_loss = 0.0\n",
        "        # ネットワークを訓練モードにする\n",
        "        net.train()\n",
        "        n = 0\n",
        "        n_acc = 0\n",
        "        # 非常に時間がかかるのでtqdmを使用してプログレスバーを出す\n",
        "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "            total=len(train_loader)):\n",
        "            xx = xx.to(device)\n",
        "            yy = yy.to(device)\n",
        "            h = net(xx)\n",
        "            loss = loss_fn(h, yy)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            n += len(xx)\n",
        "            _, y_pred = h.max(1)\n",
        "            n_acc += (yy == y_pred).float().sum().item()\n",
        "        train_losses.append(running_loss / i)\n",
        "        # 訓練データの予測精度\n",
        "        train_acc.append(n_acc / n)\n",
        "        # 検証データの予測精度\n",
        "        val_acc.append(eval_net(net, test_loader, device))\n",
        "        # このepochでの結果を表示\n",
        "        print(epoch, train_losses[-1], train_acc[-1],\n",
        "              val_acc[-1], flush=True)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYaPucmvL9D4",
        "colab_type": "text"
      },
      "source": [
        "リスト4.4　全パラメータをGPUに転送して訓練を実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgwqbNNJO-AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークの全パラメータをGPUに転送\n",
        "net.to(\"cuda:0\")\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_5zA9uk7wSW",
        "colab_type": "text"
      },
      "source": [
        "Colaboratory における圧縮ファイルの展開、ディレクトリの作成および移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYe-nXP5XVZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/lucidfrontier45/PyTorch-Book/raw/master/data/taco_and_burrito.tar.gz\n",
        "!tar xf taco_and_burrito.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5nYkICSYg3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf taco_and_burrito.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0xHRM40Nas5",
        "colab_type": "text"
      },
      "source": [
        "リスト4.5　DataLoaderを作成（<your_path>を変更している）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z8wXdTAZFYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# ImageFolder関数を使用してDatasetを作成する\n",
        "train_imgs = ImageFolder(\n",
        "    \"taco_and_burrito/train/\",\n",
        "    transform=transforms.Compose([\n",
        "      transforms.RandomCrop(224),\n",
        "      transforms.ToTensor()]\n",
        "))\n",
        "test_imgs = ImageFolder(\n",
        "    \"taco_and_burrito/test/\",\n",
        "    transform=transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_loader = DataLoader(\n",
        "    train_imgs, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(\n",
        "    test_imgs, batch_size=32, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAuOWzl-N3FS",
        "colab_type": "text"
      },
      "source": [
        "リスト4.6　クラス名とクラスインデクスの対応の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjFq2Hn0ZY4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_imgs.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm9tYrOFZuMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_imgs.class_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmp9aGmjN-Ri",
        "colab_type": "text"
      },
      "source": [
        "リスト4.7　事前学習済み（Pre-trained）のモデルのロードと定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki3tvFMmZ16Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "# 事前学習済みのresnet18をロード\n",
        "net = models.resnet18(pretrained=True)\n",
        "\n",
        "# すべてのパラメータを微分対象外にする\n",
        "for p in net.parameters():\n",
        "    p.requires_grad=False\n",
        "    \n",
        "# 最後の線形層を付け替える\n",
        "fc_input_dim = net.fc.in_features\n",
        "net.fc = nn.Linear(fc_input_dim, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFQYkYilOTKD",
        "colab_type": "text"
      },
      "source": [
        "リスト4.8　モデルの訓練関数の記述"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiy4BalMbUIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "    # DropoutやBatchNormを無効化\n",
        "    net.eval()\n",
        "    ys = []\n",
        "    ypreds = []\n",
        "    for x, y in data_loader:\n",
        "        # toメソッドで計算を実行するデバイスに転送する\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # 確率が最大のクラスを予測(リスト2.14参照)\n",
        "        # ここではforward（推論）の計算だけなので自動微分に\n",
        "        # 必要な処理はoffにして余計な計算を省く\n",
        "        with torch.no_grad():\n",
        "            _, y_pred = net(x).max(1)\n",
        "        ys.append(y)\n",
        "        ypreds.append(y_pred)\n",
        "    # ミニバッチごとの予測結果などを1つにまとめる\n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "    # 予測精度を計算\n",
        "    acc = (ys == ypreds).float().sum() / len(ys)\n",
        "    return acc.item()\n",
        "\n",
        "def train_net(net, train_loader, test_loader,\n",
        "              only_fc=True,\n",
        "              optimizer_cls=optim.Adam,\n",
        "              loss_fn=nn.CrossEntropyLoss(),\n",
        "              n_iter=10, device=\"cpu\"):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    if only_fc:\n",
        "        # 最後の線形層のパラメータのみを、\n",
        "        # optimizerに渡す\n",
        "        optimizer = optimizer_cls(net.fc.parameters())\n",
        "    else:\n",
        "        optimizer = optimizer_cls(net.parameters())\n",
        "    for epoch in range(n_iter):\n",
        "        running_loss = 0.0\n",
        "        # ネットワークを訓練モードにする\n",
        "        net.train()\n",
        "        n = 0\n",
        "        n_acc = 0\n",
        "        # 非常に時間がかかるのでtqdmを使用してプログレスバーを出す\n",
        "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "            total=len(train_loader)):\n",
        "            xx = xx.to(device)\n",
        "            yy = yy.to(device)\n",
        "            h = net(xx)\n",
        "            loss = loss_fn(h, yy)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            n += len(xx)\n",
        "            _, y_pred = h.max(1)\n",
        "            n_acc += (yy == y_pred).float().sum().item()\n",
        "        train_losses.append(running_loss / i)\n",
        "        # 訓練データの予測精度\n",
        "        train_acc.append(n_acc / n)\n",
        "        # 検証データの予測精度\n",
        "        val_acc.append(eval_net(net, test_loader, device))\n",
        "        # このepochでの結果を表示\n",
        "        print(epoch, train_losses[-1], train_acc[-1],\n",
        "              val_acc[-1], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUmqR7K6OZil",
        "colab_type": "text"
      },
      "source": [
        "リスト4.9　全パラメータをGPUに転送して訓練を実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq6a9HQTch__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークの全パラメータをGPUに転送\n",
        "net.to(\"cuda:0\")\n",
        "\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCYU1Q1KQQBu",
        "colab_type": "text"
      },
      "source": [
        "リスト4.10　入力をそのまま出力するダミーの層を作り、fcを置き換える"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vT1cElbcvyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IdentityLayer(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "    \n",
        "net = models.resnet18(pretrained=True)\n",
        "for p in net.parameters():\n",
        "    p.requires_grad=False\n",
        "net.fc = IdentityLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5npRykYxQWB0",
        "colab_type": "text"
      },
      "source": [
        "リスト4.11　筆者が作成したCNNモデルの実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qupx3SbAhrfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_net = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.Conv2d(32, 64, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.Conv2d(64, 128, 5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(128),\n",
        "    FlattenLayer()\n",
        ")\n",
        "\n",
        "# 畳み込みによって最終的にどのようなサイズになっているかを、\n",
        "# 実際にデータを入れて確認する\n",
        "test_input = torch.ones(1, 3, 224, 224)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "\n",
        "# 最終的なCNN\n",
        "net = nn.Sequential(\n",
        "    conv_net,\n",
        "    nn.Linear(conv_output_size, 2)\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "train_net(net, train_loader, test_loader, n_iter=10,\n",
        "          only_fc=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR4VlalN7jsM",
        "colab_type": "text"
      },
      "source": [
        "Colaboratory における圧縮ファイルの展開、ディレクトリの作成および移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEC-pI4xPHly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
        "!tar xf lfw-deepfunneled.tgz\n",
        "!mkdir lfw-deepfunneled/train\n",
        "!mkdir lfw-deepfunneled/test\n",
        "!mv lfw-deepfunneled/[A-W]* lfw-deepfunneled/train\n",
        "!mv lfw-deepfunneled/[X-Z]* lfw-deepfunneled/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI1MEPhDJ2w2",
        "colab_type": "text"
      },
      "source": [
        "リスト4.12　32×32ピクセルの画像を128×128ピクセルに拡大する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKyWTGXSikTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DownSizedPairImageFolder(ImageFolder):\n",
        "    def __init__(self, root, transform=None, \n",
        "                 large_size=128, small_size=32, **kwds):\n",
        "        super().__init__(root, transform=transform, **kwds)\n",
        "        self.large_resizer = transforms.Resize(large_size)\n",
        "        self.small_resizer = transforms.Resize(small_size)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        path, _ = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "        \n",
        "        # 読み取った画像を128×128ピクセルと32×32ピクセルにリサイズする\n",
        "        large_img = self.large_resizer(img)\n",
        "        small_img = self.small_resizer(img)\n",
        "            \n",
        "        # その他の変換を適用する\n",
        "        if self.transform is not None:\n",
        "            large_img = self.transform(large_img)\n",
        "            small_img = self.transform(small_img)\n",
        "        \n",
        "        # 32ピクセルの画像と128ピクセルの画像を返す\n",
        "        return small_img, large_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzYoPjpfJ8Mu",
        "colab_type": "text"
      },
      "source": [
        "リスト4.13　訓練用と検証用のDataLoaderを作成（<your_path>を変更している）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96PhAe7h_fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = DownSizedPairImageFolder(\n",
        "    \"lfw-deepfunneled/train\",\n",
        "    transform=transforms.ToTensor())\n",
        "test_data = DownSizedPairImageFolder(\n",
        "    \"lfw-deepfunneled/test\",\n",
        "    transform=transforms.ToTensor())\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, \n",
        "                          shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdA7XWlOLMBP",
        "colab_type": "text"
      },
      "source": [
        "リスト4.14　モデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2arZPcFzFQEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Conv2d(3, 256, 4,\n",
        "              stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.Conv2d(256, 512, 4,\n",
        "              stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ConvTranspose2d(512, 256, 4,\n",
        "                       stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ConvTranspose2d(256, 128, 4,\n",
        "                       stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ConvTranspose2d(128, 64, 4,\n",
        "                       stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ConvTranspose2d(64, 3, 4,\n",
        "                       stride=2, padding=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-pAccxxLW5c",
        "colab_type": "text"
      },
      "source": [
        "リスト4.15　PSNRの計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmjrKNJzGkko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def psnr(mse, max_v=1.0):\n",
        "    return 10 * math.log10(max_v**2 / mse)\n",
        "  \n",
        "# 評価のヘルパー関数\n",
        "def eval_net(net, data_loader, device=\"cpu\"):\n",
        "  \n",
        "    # DropoutやBatchNormを無効化\n",
        "    net.eval()\n",
        "    ys = []\n",
        "    ypreds = []\n",
        "    for x, y in data_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = net(x)\n",
        "        ys.append(y)\n",
        "        ypreds.append(y_pred)\n",
        "    \n",
        "    # ミニバッチごとの予測結果などを1つにまとめる\n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "    \n",
        "    # 予測精度(MSE)を計算\n",
        "    score = nn.functional.mse_loss(ypreds, ys).item()\n",
        "    return score\n",
        "\n",
        "# 訓練のヘルパー関数\n",
        "def train_net(net, train_loader, test_loader,\n",
        "              optimizer_cls=optim.Adam,\n",
        "              loss_fn=nn.MSELoss(),\n",
        "              n_iter=10, device=\"cpu\"):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    optimizer = optimizer_cls(net.parameters())\n",
        "    for epoch in range(n_iter):\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # ネットワークを訓練モードにする\n",
        "        net.train()\n",
        "        n = 0\n",
        "        score = 0\n",
        "        \n",
        "        # 非常に時間がかかるのでtqdmを\n",
        "        # 使用してプログレスバーを出す\n",
        "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
        "            total=len(train_loader)):\n",
        "            xx = xx.to(device)\n",
        "            yy = yy.to(device)\n",
        "            y_pred = net(xx)\n",
        "            loss = loss_fn(y_pred, yy)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            n += len(xx)\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        \n",
        "        # 検証データの予測精度\n",
        "        val_acc.append(eval_net(net, test_loader, device))\n",
        "        \n",
        "        # このepochでの結果を表示\n",
        "        print(epoch, train_losses[-1], \n",
        "              psnr(train_losses[-1]), psnr(val_acc[-1]), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc9GHSfDLuvs",
        "colab_type": "text"
      },
      "source": [
        "リスト4.16　複数回の演算（10回）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-fYbpVaG5En",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.to(\"cuda:0\")\n",
        "train_net(net, train_loader, test_loader, device=\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8CseDWEOEz7",
        "colab_type": "text"
      },
      "source": [
        "リスト4.17　画像を拡大してオリジナルと比較する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBFnNnMzG9NY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "# テストのデータセットからランダムに4つずつ取り出すDataLoader\n",
        "random_test_loader = DataLoader(test_data, batch_size=4, shuffle=True)\n",
        "\n",
        "# DataLoaderをPythonのイテレータに変換し、4つ例を取り出す\n",
        "it = iter(random_test_loader)\n",
        "x, y = next(it)\n",
        "\n",
        "# Bilinearで拡大\n",
        "bl_recon = torch.nn.functional.upsample(x, 128, mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "# CNNで拡大\n",
        "yp = net(x.to(\"cuda:0\")).to(\"cpu\")\n",
        "\n",
        "# torch.catでオリジナル,Bilinear,CNNの画像を結合し\n",
        "# save_imageで画像ファイルに書き出し\n",
        "save_image(torch.cat([y, bl_recon, yp], 0), \"cnn_upscale.jpg\", nrow=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FDFB9lVPhVi",
        "colab_type": "text"
      },
      "source": [
        "生成ファイルの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JI_xl3RJ_gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwIiGuKoPnf7",
        "colab_type": "text"
      },
      "source": [
        "Colaboratory における画像の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgbOhjw5O5pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image,display_jpeg\n",
        "display_jpeg(Image('cnn_upscale.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utuVlzjX9HGZ",
        "colab_type": "text"
      },
      "source": [
        "Colaboratory における圧縮ファイルの展開、ディレクトリの作成および移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjmZ65acHyvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!tar xf 102flowers.tgz\n",
        "!mkdir oxford-102\n",
        "!mkdir oxford-102/jpg\n",
        "!mv jpg/*.jpg oxford-102/jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzR0IQWXOh2k",
        "colab_type": "text"
      },
      "source": [
        "リスト4.18　DataLoaderの準備（<your_path>を変更している）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWYG2ifen1Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_data = ImageFolder(\"oxford-102/\",\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize(80),\n",
        "        transforms.CenterCrop(64),\n",
        "        transforms.ToTensor()\n",
        "]))\n",
        "\n",
        "batch_size = 64\n",
        "img_loader = DataLoader(img_data, batch_size=batch_size,\n",
        "                        shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgEOSvTKOxdO",
        "colab_type": "text"
      },
      "source": [
        "リスト4.19　画像の生成モデルを組み立てる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bSgo88zoMSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nz = 100\n",
        "ngf = 32\n",
        "\n",
        "class GNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, \n",
        "                               4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4,\n",
        "                               4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2,\n",
        "                               4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf,\n",
        "                               4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ngf, 3,\n",
        "                               4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrUFAsTGO1JG",
        "colab_type": "text"
      },
      "source": [
        "リスト4.20　画像の識別モデルを組み立てる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M-lMEbapC3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ndf = 32\n",
        "\n",
        "class DNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main(x)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIVqFMkAPCHf",
        "colab_type": "text"
      },
      "source": [
        "リスト4.21　訓練関数の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDinUT68pnWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = DNet().to(\"cuda:0\")\n",
        "g = GNet().to(\"cuda:0\")\n",
        "\n",
        "# Adamのパラメータは元論文の提案値\n",
        "opt_d = optim.Adam(d.parameters(),\n",
        "    lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_g = optim.Adam(g.parameters(),\n",
        "    lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# クロスエントロピーを計算するための補助変数など\n",
        "ones = torch.ones(batch_size).to(\"cuda:0\")\n",
        "zeros = torch.zeros(batch_size).to(\"cuda:0\")\n",
        "loss_f = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# モニタリング用のz\n",
        "fixed_z = torch.randn(batch_size, nz, 1, 1).to(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3sW5nczPG8Q",
        "colab_type": "text"
      },
      "source": [
        "リスト4.22　訓練関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV6AD1SvqLyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "def train_dcgan(g, d, opt_g, opt_d, loader):\n",
        "    # 生成モデル、識別モデルの目的関数の追跡用の配列\n",
        "    log_loss_g = []\n",
        "    log_loss_d = []\n",
        "    for real_img, _ in tqdm.tqdm(loader):\n",
        "        batch_len = len(real_img)\n",
        "        \n",
        "         # 実際の画像をGPUにコピー\n",
        "        real_img = real_img.to(\"cuda:0\")\n",
        "        \n",
        "         # 偽画像を乱数と生成モデルから作る\n",
        "        z = torch.randn(batch_len, nz, 1, 1).to(\"cuda:0\")\n",
        "        fake_img = g(z)\n",
        "        \n",
        "        # 後で使用するので偽画像の値のみ取り出しておく\n",
        "        fake_img_tensor = fake_img.detach()\n",
        "        \n",
        "        # 偽画像に対する生成モデルの評価関数を計算する\n",
        "        out = d(fake_img)\n",
        "        loss_g = loss_f(out, ones[: batch_len])\n",
        "        log_loss_g.append(loss_g.item())\n",
        "        \n",
        "        # 計算グラフが生成モデルと識別モデルの両方に\n",
        "        # 依存しているので両者とも勾配をクリアしてから\n",
        "        # 微分の計算とパラメータ更新を行う\n",
        "        d.zero_grad(), g.zero_grad()\n",
        "        loss_g.backward()\n",
        "        opt_g.step()\n",
        "\n",
        "        # 実際の画像に対する識別モデルの評価関数を計算\n",
        "        real_out = d(real_img)\n",
        "        loss_d_real = loss_f(real_out, ones[: batch_len])\n",
        "        \n",
        "        # PyTorchでは同じTensorを含んだ計算グラフに対して\n",
        "        # 2回backwardを行うことができないので保存してあった\n",
        "        # Tensorを使用して無駄な計算を省く\n",
        "        fake_img = fake_img_tensor\n",
        "        \n",
        "        # 偽画像に対する識別モデルの評価関数の計算\n",
        "        fake_out = d(fake_img_tensor)\n",
        "        loss_d_fake = loss_f(fake_out, zeros[: batch_len])\n",
        "        \n",
        "        # 実偽の評価関数の合計値\n",
        "        loss_d = loss_d_real + loss_d_fake\n",
        "        log_loss_d.append(loss_d.item())\n",
        "        \n",
        "        # 識別モデルの微分計算とパラメータ更新\n",
        "        d.zero_grad(), g.zero_grad()\n",
        "        loss_d.backward()\n",
        "        opt_d.step()\n",
        "        \n",
        "    return mean(log_loss_g), mean(log_loss_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8Kn21rP_vC",
        "colab_type": "text"
      },
      "source": [
        "リスト4.23　DCGANの訓練（<your_path>を変更している）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5mxpchxqXFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(300):\n",
        "    train_dcgan(g, d, opt_g, opt_d, img_loader)\n",
        "    # 10回の繰り返しごとに学習結果を保存する\n",
        "    if epoch % 10 == 0:\n",
        "        # パラメータの保存\n",
        "        torch.save(\n",
        "            g.state_dict(),\n",
        "            \"oxford-102/g_{:03d}.prm\".format(epoch),\n",
        "            pickle_protocol=4)\n",
        "        torch.save(\n",
        "            d.state_dict(),\n",
        "            \"oxford-102/d_{:03d}.prm\".format(epoch),\n",
        "            pickle_protocol=4)\n",
        "        # モニタリング用のzから生成した画像を保存\n",
        "        generated_img = g(fixed_z)\n",
        "        save_image(generated_img,\n",
        "                   \"oxford-102/{:03d}.jpg\".format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmLMvL--QY_i",
        "colab_type": "text"
      },
      "source": [
        "生成ファイルの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLGLd_hTWyBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls oxford-102/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrB0-bb1RKe2",
        "colab_type": "text"
      },
      "source": [
        "Colaboratory における画像の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEtTL8t-XAwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image,display_jpeg\n",
        "display_jpeg(Image('oxford-102/000.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}